# Notes-RL
Collection of paper notes (PDF+LaTeX) in reinforcement learning, with compact summary and detailed mathematical derivations.

# Textbook
- [Sutton, Introduction to Reinforcement Learning, 2nd edition](/Sutton%20-%20Introduction%20to%20RL)

# Derivative-Free Optimization
- Szita et al., Learning Teris using the Noisy Cross-Entropy Method

# RL
- Nachum et al., Bridging the Gap Between Valud and Policy Based Reinforcement Learning

# Policy Gradients
- Williams, Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning
- Silver et al., A3C 
  -- Only focus on A2C version. Asynchronuous not very important
- Precup et al., DRL that Matters
- Gu et al. Continuous deep Q-learning with model-based acceleration
- Schulman, High-dimensional continuous control using generalized advantage estimation
- Schulman, Benchmarking deep reinforcement learning for continuous control
- Kakade, Approximately Optimal Approximate Reinforcement Learning
- Silver et al., DPG
- Silver et al., DDPG
- Schulman et al., TRPO
- Schulman et al., PPO
- Liu et al., Stein Variational Policy Gradient
- Gruslys et al., The Reactor
- Wang et al., Sample Efficient Actor-Critic with Experience Reply
- Gu et al., Q-Prop
- Gu et al., Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning
- Gu et al., Continuous Deep Q-Learning with Model-based Acceleration

# DQN
- Silver et al., Human-level control through deep reinforcement learning
- Silver et al. Double Q-Learning
- Silver et al. Dueling network architectures for deep reinforcement learning
- Silver et al. Prioritized experience replay
- Silver et al., Rainbow: Combining Improvements in DRL
- Bellemare et al., A Distributional Perspective on Reinforcement Learning
- Tamar et al., VIN

# Model-based RL & Planning
- Henaff et al., Model-Based Planning in Discrete Action Spaces
  - Paper, Notes
- Silver et al., The Predictron: End-To-End Learning and Planning
- Pascanu et al., Learning model-based planning from scratch
- Weber et al., Imagination-Augmented Agents for Deep Reinforcement Learning
- Li et al., Iterative Linear Quadratic Regulator Design for Nonlinear Biological Movement Systems
- Andreas et al., Learning to Plan Without a Planner
- Chockalingam et al., Differentiable Neural Planners with Temporally Extended Actions
- Karkus et al., QMDP-Net
- Mishra et al., Prediction and Control with Temporal Segment Models
- Metz et al., Discrete Sequential Prediction of Continuous Actions for Deep RL
- Moerland et al., Learning Multimodal Transition Dynamics for Model-Based Reinforcement Learning
- Chiappa et al., Recurrent Environment Simulators

# Exploration
- Ostand et al. Deep Exploration via Bootstrapped DQN
- Osband et al. (More) efficient reinforcement learning via posterior sampling
- Houthooft et al., VIME
- Ostrovski et al., Count-Based Exploration with Neural Density Models
- Tang et al., #Exploration: A Study of Count-based Exploration for Deep Reinforcement Learning
- Fortunato et al., Noisy Networks for Exploration
- Plappert et al., Parameter Space Noise for Exploration

# Curriculum (Lifelong) Reinforcement Learning
- [Schmidhuber, PowerPlay: Training an increasingly general problem solver by continually searching for the simplest still unsolvable problem](/PowerPlay)

# Bayesian RL
- Tamar et al., Bayesian Reinforcement Learning: A Survey

# Neuroscience
- Botvinick et al., The hippocampus as a predictive map, Nature
- Hassabis et al., Neuroscience-Inspired Artificial Intelligence

# Deep learning
- Dumoulin, A guide to convolution arithmetic for deep learning
- Bottou, Stochastic Gradient Descent Tricks
- Kingma et al., Auto-Encoding Variational Bayes

# Bayesian Neural Networks
- Blundell et al., Weight Uncertainty in Neural Networks
- Blundell et al., Bayesian Recurrent Neural Networks
- Gal et al., What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision ?
- Hernandez-Lobato et al., Black-Box alpha-Divergence Minimization
- Blei et al., Variational Inference: A Review for Statisticians
- Roeder et al., Sticking the Landing: Simple, Lower-Variance Gradient Estimators for Variational Inference
- Lakshminarayanan et al., Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles
